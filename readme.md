# Projet Hadoop TP Final

![Hadoop](https://img.shields.io/badge/Hadoop-3.3.6-blue)
![Docker](https://img.shields.io/badge/Docker-latest-brightgreen)

## ğŸ¯ Description

Bienvenue dans le projet **Hadoop TP Final**. Ce projet vise Ã  implÃ©menter un systÃ¨me de recommandation d'amis basÃ© sur un algorithme de filtrage collaboratif en utilisant des donnÃ©es massives traitÃ©es via Apache Hadoop. Le but est de simuler un mÃ©canisme de recommandation que l'on retrouve sur des plateformes comme Facebook, LinkedIn ou Twitter, en utilisant les relations existantes entre utilisateurs pour gÃ©nÃ©rer des recommandations pertinentes. Ce TP permet de comprendre comment les systÃ¨mes de recommandation fonctionnent Ã  grande Ã©chelle.

Le projet se compose principalement de la mise en Å“uvre d'un pipeline de traitement de donnÃ©es massives avec Hadoop. Il inclut des Ã©tapes pour importer des donnÃ©es dans HDFS, manipuler ces donnÃ©es avec des commandes Hadoop, et exÃ©cuter un algorithme de filtrage collaboratif.

## ğŸ› ï¸ PrÃ©requis

- Hadoop
- Docker
- Git
- Maven ou Gradle
- HDFS (Hadoop Distributed File System)


## ğŸ“¦ Installation et Configuration

### 1. Clonage du Projet
```bash
# Cloner le repo
git clone https://github.com/votre-username/hadoop-tp-final.git
cd hadoop-tp-final
```

### 2. Construction de l'Image Docker
```bash
# Naviguer vers le dossier deploy
cd ./deploy/

# Construire l'image Docker
docker buildx build -t hadoop-tp-final-img .
```

### 3. DÃ©marrage du Conteneur
```bash
# Lancer le conteneur avec les volumes montÃ©s
docker run -d --rm \
  -p 8088:8088 \
  -p 9870:9870 \
  -p 9864:9864 \
  -v "C:\Julie\MIN-5A\3- Outil big data\TP_final\hadoop-tp3\data:/tmp/data" \
  -v "C:\Julie\MIN-5A\3- Outil big data\TP_final\hadoop-tp3\jars:/tmp/jars" \
  --name conteneur_TP_Final \
  hadoop-tp-final-img
```

## ğŸ”„ Configuration HDFS et Import des DonnÃ©es

### 1. Connexion au Conteneur
```bash
docker exec -it conteneur_TP_Final su - epfuser
```

### 2. CrÃ©ation et VÃ©rification de la Structure HDFS
```bash 
# CrÃ©er le rÃ©pertoire pour les relations
hdfs dfs -mkdir -p /input/relationships

# VÃ©rifier la structure HDFS
hdfs dfs -ls /
hadoop fs -ls /input/relationships
```
### 3. Import des DonnÃ©es dans HDFS
```bash
# Copier les donnÃ©es vers HDFS
hadoop fs -put /tmp/data/relationships/data.txt /input/relationships/
hadoop fs -put /tmp/data/relationships/testdata.txt /input/relationships/  
```

### 4. VÃ©rification des DonnÃ©es Sources
```bash
# VÃ©rifier la prÃ©sence du fichier de donnÃ©es
ls /tmp/data/relationships/
# RÃ©sultat attendu :
# data.txt
```

## ğŸ“¦ Compilation et DÃ©ploiement

### 1. Compilation du Projet
```bash
# Quitter la session epfuser
exit

# Compiler le projet avec Maven
mvn clean install
```

### 2. DÃ©ploiement dans le Conteneur
```bash
# Copier le JAR dans le conteneur
docker cp "C:\Julie\MIN-5A\3- Outil big data\TP_final\hadoop-tp3\p-collaborative-filtering-job-1\target\hadoop-tp3-collaborativeFiltering-job1-1.0.jar" conteneur_TP_Final:/tmp/jars/

# Se reconnecter au conteneur et vÃ©rifier le dÃ©ploiement
docker exec -it conteneur_TP_Final su - epfuser
cd /tmp/jars
ls -l

# RÃ©sultat attendu :
# total 8
# -rwxr-xr-x 1 root root 5916 Jan 12 18:34 hadoop-tp3-collaborativeFiltering-job1-1.0.jar
```

### 3. ExÃ©cution du Job MapReduce
```bash
# Lancer le job MapReduce
hadoop jar /tmp/jars/hadoop-tp3-collaborativeFiltering-job1-1.0.jar org.epf.hadoop.colfil1.ColFilJob1 /input/relationships/data.txt /output/job1

```
## ProcÃ©dure pour tester le code
```bash
#supprimer l'ancien jar du conteneur
docker exec -it conteneur_TP_Final su - epfuser
cd /tmp/jars
ls -l
#verifier si il y a qqchose
rm rm hadoop-tp3-collaborativeFiltering-job1-1.0.jar
rm rm hadoop-tp3-collaborativeFiltering-job2-1.0.jar
ls -l
exit
#recompiler le projet pour avoir un nouveau jar
mvn clean install
#remettre le nouveau jar dans le conteneur
docker cp "C:\Julie\MIN-5A\3- Outil big data\TP_final\hadoop-tp3\p-collaborative-filtering-job-1\target\hadoop-tp3-collaborativeFiltering-job1-1.0.jar" conteneur_TP_Final:/tmp/jars/
docker cp "C:\Julie\MIN-5A\3- Outil big data\TP_final\hadoop-tp3\p-collaborative-filtering-job-2\target\hadoop-tp3-collaborativeFiltering-job2-1.0.jar" conteneur_TP_Final:/tmp/jars/
docker exec -it conteneur_TP_Final su - epfuser
#verifier si le nouveau jar est bien la
cd /tmp/jars
ls -l
#suprimer l'ancien output
hdfs dfs -rm -r /output/job1
hdfs dfs -rm -r /output/job2
#relancer le job
hadoop jar /tmp/jars/hadoop-tp3-collaborativeFiltering-job1-1.0.jar org.epf.hadoop.colfil1.ColFilJob1 /input/relationships/data.txt /output/job1
hadoop jar /tmp/jars/hadoop-tp3-collaborativeFiltering-job2-1.0.jar org.epf.hadoop.colfil1.ColFilJob2 /output/job1 /output/job2
#lancer les tests
hadoop jar /tmp/jars/hadoop-tp3-collaborativeFiltering-job1-1.0.jar org.epf.hadoop.colfil1.ColFilJob1 /input/relationships/testdata.txt /output/job1test
hadoop jar /tmp/jars/hadoop-tp3-collaborativeFiltering-job2-1.0.jar org.epf.hadoop.colfil1.ColFilJob2 /output/job1test /output/job2test
#verifier le resultat
hdfs dfs -cat /output/job1/part-r-00000
hdfs dfs -ls /output/job1
hdfs dfs -cat /output/job2/part-r-00000
hdfs dfs -ls /output/job2
#afficher les resultats des tests
hdfs dfs -cat /output/job1test/part-r-00000
hdfs dfs -cat /output/job1test/part-r-00001
hdfs dfs -cat /output/job2test/part-r-00000
hdfs dfs -cat /output/job2test/part-r-00001
```
### Extraire les RÃ©sultats et les afficher dans le PC en local
#### Dans le conteneur
```bash
mkdir -p /home/epfuser/relationships/job1
hdfs dfs -get /output/job1 /home/epfuser/relationships/job1
ls /home/epfuser/relationships/job1  # Pour vÃ©rifier que les fichiers ont Ã©tÃ© copiÃ©s
exit  # Pour sortir du conteneur
```
#### Dans le PC local
```bash
mkdir -p "C:\Julie\MIN-5A\3- Outil big data\TP_final\hadoop-tp3\data\relationships\job1"
docker cp "conteneur_TP_Final:/home/epfuser/relationships/job1" "C:\Julie\MIN-5A\3- Outil big data\TP_final\hadoop-tp3\data\relationships\job1"
```
regler le pb de connexion au resource manager lors de l'execution du job 2, et permetre d'acceder a l'interface graphique sur http://localhost:8088
```bash
docker exec -it conteneur_TP_Final su - epfuser
export YARN_RESOURCEMANAGER_USER=epfuser
export YARN_NODEMANAGER_USER=epfuser
start-yarn.sh
jps
```
## ğŸ“ Structure du Projet

```
hadoop-tp3/
â”œâ”€â”€ .idea/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ relationships/
â”‚       â””â”€â”€ data.txt
â”‚       â””â”€â”€ testdata.txt
â”œâ”€â”€ .gitkeep
â”œâ”€â”€ schema_des_donnees_test.png
â”œâ”€â”€ deploy/
â”œâ”€â”€ jars/
â”‚   â””â”€â”€ p-collaborative-filtering-job-1/
â”‚       â””â”€â”€ src/
â”‚           â””â”€â”€ main/
â”‚               â””â”€â”€ java/
â”‚                   â””â”€â”€ org/
â”‚                       â””â”€â”€ epf/
â”‚                           â””â”€â”€ hadoop/
â”‚                               â””â”€â”€ colfil1/
â”‚                                   â”œâ”€â”€ ColFilJob1.java
â”‚                                   â”œâ”€â”€ Relationship.java
â”‚                                   â”œâ”€â”€ RelationshipInputFormat.java
â”‚                                   â””â”€â”€ RelationshipRecordReader.java
â”‚   â””â”€â”€ p-collaborative-filtering-job-2/
â”‚       â””â”€â”€ src/
â”‚           â””â”€â”€ main/
â”‚               â””â”€â”€ java/
â”‚                   â””â”€â”€ org/
â”‚                       â””â”€â”€ epf/
â”‚                           â””â”€â”€ hadoop/
â”‚                               â””â”€â”€ colfil2/
â”‚                                   â””â”€â”€ ColFilJob2.java
â”‚   â””â”€â”€ p-collaborative-filtering-job-3/
â”‚       â””â”€â”€ src/
â”‚           â””â”€â”€ main/
â”‚               â””â”€â”€ java/
â”‚                   â””â”€â”€ org/
â”‚                       â””â”€â”€ epf/
â”‚                           â””â”€â”€ hadoop/
â”‚                               â””â”€â”€ colfil3/
â”‚                                   â””â”€â”€ ColFilJob3.java
â”œâ”€â”€ .gitattributes
â”œâ”€â”€ .gitignore
â”œâ”€â”€ pom.xml
â””â”€â”€ README.md

```

## ğŸ” Points ClÃ©s

- `deploy/`: Configuration Docker
- `data/`: DonnÃ©es d'entrÃ©e
- `jars/`: ExÃ©cutables Java

## ğŸ“Š Ports ExposÃ©s

| Port  | Service                   |
|-------|---------------------------|
| 8088  | ResourceManager Web UI     |
| 9870  | NameNode Web UI            |
| 9864  | DataNode Web UI            |

## ğŸ”— Liens Utiles

- [Documentation Hadoop](https://hadoop.apache.org/docs/current/)
- [Documentation Docker](https://docs.docker.com/)